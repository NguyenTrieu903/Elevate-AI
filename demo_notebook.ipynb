{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39f5e247",
   "metadata": {},
   "source": [
    "# RAG Chatbot System - Interactive Demo\n",
    "\n",
    "This notebook demonstrates the RAG (Retrieval-Augmented Generation) chatbot system with FAISS vector search, Langchain workflows, and Azure OpenAI function calling.\n",
    "\n",
    "## Features Demonstrated:\n",
    "- **Vector Search**: FAISS-based document retrieval\n",
    "- **RAG Pipeline**: Langchain retrieval-augmented generation\n",
    "- **Function Calling**: Dynamic external data access\n",
    "- **Multiple Use Cases**: IT Helpdesk, Customer Support, HR Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c701bebe",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ee00d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\tuanph16\\Downloads\\chatbot 1\\ws4\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProject root: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Import our RAG system components\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrag_system\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_interface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RAGChatbot\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrag_system\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvector_store\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VectorStore\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrag_system\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunction_calling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FunctionCaller\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tuanph16\\Downloads\\chatbot 1\\ws4\\rag_system\\chat_interface.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Any, List, Optional\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mretrieval_chain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RetrievalChain, ConversationManager\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunction_calling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FunctionCaller\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tuanph16\\Downloads\\chatbot 1\\ws4\\rag_system\\retrieval_chain.py:6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Dict, Any, Optional, Tuple\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage, AIMessage, BaseMessage\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate, MessagesPlaceholder\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_openai'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "# Import our RAG system components\n",
    "from rag_system.chat_interface import RAGChatbot\n",
    "from rag_system.vector_store import VectorStore\n",
    "from rag_system.function_calling import FunctionCaller\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "print(\"âœ… Imports completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2542a8fc",
   "metadata": {},
   "source": [
    "## 2. Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e020ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if environment variables are configured\n",
    "required_vars = [\n",
    "    \"AZURE_OPENAI_ENDPOINT\",\n",
    "    \"AZURE_OPENAI_API_KEY\",\n",
    "    \"AZURE_OPENAI_API_VERSION\"\n",
    "]\n",
    "\n",
    "print(\"Environment Configuration Check:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "all_configured = True\n",
    "for var in required_vars:\n",
    "    value = os.getenv(var)\n",
    "    if value:\n",
    "        print(f\"âœ… {var}: Configured\")\n",
    "    else:\n",
    "        print(f\"âŒ {var}: Missing\")\n",
    "        all_configured = False\n",
    "\n",
    "if all_configured:\n",
    "    print(\"\\nðŸŽ‰ All environment variables are configured!\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Please configure missing environment variables in your .env file\")\n",
    "    print(\"Copy .env.template to .env and fill in your Azure OpenAI credentials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc6a1ca",
   "metadata": {},
   "source": [
    "## 3. Vector Store Demo\n",
    "\n",
    "First, let's demonstrate the FAISS vector store functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb8c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ” Testing Vector Store...\\n\")\n",
    "\n",
    "# Create vector store for IT helpdesk\n",
    "vector_store = VectorStore(\"it_helpdesk\")\n",
    "\n",
    "# Load IT helpdesk documents\n",
    "from mock_data.it_helpdesk import get_it_helpdesk_data\n",
    "documents = get_it_helpdesk_data()\n",
    "\n",
    "print(f\"ðŸ“š Loaded {len(documents)} documents\")\n",
    "print(f\"Sample document: {documents[0]['page_content'][:100]}...\")\n",
    "\n",
    "# Create or load index\n",
    "vector_store.create_index(documents)\n",
    "\n",
    "# Get stats\n",
    "stats = vector_store.get_stats()\n",
    "print(f\"\\nðŸ“Š Vector Store Stats: {stats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6dd636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test similarity search\n",
    "test_queries = [\n",
    "    \"computer is slow\",\n",
    "    \"password reset\",\n",
    "    \"printer not working\",\n",
    "    \"VPN connection\"\n",
    "]\n",
    "\n",
    "print(\"ðŸ” Testing Similarity Search:\\n\")\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"Query: '{query}'\")\n",
    "    results = vector_store.search(query, k=2)\n",
    "\n",
    "    for i, result in enumerate(results, 1):\n",
    "        score = result['score']\n",
    "        content = result['content'][:80] + \"...\"\n",
    "        category = result['metadata'].get('category', 'N/A')\n",
    "        print(f\"  {i}. [{category}] Score: {score:.3f} - {content}\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2e1b5b",
   "metadata": {},
   "source": [
    "## 4. Function Calling Demo\n",
    "\n",
    "Now let's test the Azure OpenAI function calling capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78750825",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”§ Testing Function Calling...\\n\")\n",
    "\n",
    "# Create function caller for IT helpdesk\n",
    "function_caller = FunctionCaller(\"it_helpdesk\")\n",
    "\n",
    "# Show available functions\n",
    "functions = list(function_caller.functions.keys())\n",
    "print(f\"ðŸ“‹ Available Functions ({len(functions)}):\")\n",
    "for func in functions:\n",
    "    description = function_caller.functions[func].description\n",
    "    print(f\"  â€¢ {func}: {description}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255b6a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test individual functions\n",
    "print(\"ðŸ§ª Testing Individual Functions:\\n\")\n",
    "\n",
    "# Test device status check\n",
    "device_result = function_caller.call_function(\n",
    "    \"check_device_status\",\n",
    "    {\"device_id\": \"printer01\"}\n",
    ")\n",
    "print(f\"Device Status for 'printer01': {device_result}\")\n",
    "\n",
    "# Test software info\n",
    "software_result = function_caller.call_function(\n",
    "    \"get_software_info\",\n",
    "    {\"software_name\": \"microsoft_office\"}\n",
    ")\n",
    "print(f\"\\nSoftware Info for 'microsoft_office': {software_result}\")\n",
    "\n",
    "# Test solution search\n",
    "solution_result = function_caller.call_function(\n",
    "    \"search_it_solutions\",\n",
    "    {\"keywords\": [\"slow\", \"performance\"]}\n",
    ")\n",
    "print(f\"\\nSolutions for 'slow performance': {solution_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e2497c",
   "metadata": {},
   "source": [
    "## 5. Complete RAG Chatbot Demo\n",
    "\n",
    "Now let's test the complete RAG chatbot with both retrieval and function calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6af4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ¤– Initializing Complete RAG Chatbot...\\n\")\n",
    "\n",
    "# Create chatbot for IT helpdesk\n",
    "chatbot = RAGChatbot(use_case=\"it_helpdesk\", enable_functions=True)\n",
    "\n",
    "# Get chatbot statistics\n",
    "stats = chatbot.get_chatbot_stats()\n",
    "print(\"ðŸ“Š Chatbot Statistics:\")\n",
    "print(f\"  Use Case: {stats['use_case']}\")\n",
    "print(f\"  Functions Enabled: {stats['functions_enabled']}\")\n",
    "print(f\"  Available Functions: {stats['functions']['total_functions']}\")\n",
    "print(f\"  Vector Store Documents: {stats['retrieval_chain']['vector_store']['total_documents']}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8e16fb",
   "metadata": {},
   "source": [
    "### Test Different Types of Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4932e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test queries that should use RAG retrieval\n",
    "rag_queries = [\n",
    "    \"My computer is running very slowly, what should I do?\",\n",
    "    \"How do I reset my password?\",\n",
    "    \"I can't connect to the company VPN\"\n",
    "]\n",
    "\n",
    "print(\"ðŸ“š Testing RAG Retrieval Queries:\\n\")\n",
    "\n",
    "for i, query in enumerate(rag_queries, 1):\n",
    "    print(f\"{i}. Query: {query}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    response = chatbot.chat(query)\n",
    "\n",
    "    print(f\"Answer: {response['answer']}\")\n",
    "    print(f\"Method: {response['method']}\")\n",
    "\n",
    "    if response.get('sources'):\n",
    "        print(f\"Sources: {', '.join(response['sources'])}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d934d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test queries that should trigger function calls\n",
    "function_queries = [\n",
    "    \"What's the status of printer01?\",\n",
    "    \"Can you check if server02 is working?\",\n",
    "    \"Tell me about Visual Studio software\"\n",
    "]\n",
    "\n",
    "print(\"ðŸ”§ Testing Function Calling Queries:\\n\")\n",
    "\n",
    "for i, query in enumerate(function_queries, 1):\n",
    "    print(f\"{i}. Query: {query}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    response = chatbot.chat(query)\n",
    "\n",
    "    print(f\"Answer: {response['answer']}\")\n",
    "    print(f\"Method: {response['method']}\")\n",
    "\n",
    "    if response.get('function_calls_made'):\n",
    "        print(f\"Function Calls Made: {response['function_calls_made']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543f658f",
   "metadata": {},
   "source": [
    "## 6. Multi-Use Case Demo\n",
    "\n",
    "Let's test different use cases to show the versatility of the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968bd17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cases = [\"customer_support\", \"hr_assistant\"]\n",
    "\n",
    "test_scenarios = {\n",
    "    \"customer_support\": [\n",
    "        \"How can I track my order?\",\n",
    "        \"What's the status of order ORD123456?\",\n",
    "        \"How much would shipping cost for a $75 order?\"\n",
    "    ],\n",
    "    \"hr_assistant\": [\n",
    "        \"How do I request time off?\",\n",
    "        \"What's my leave balance for employee EMP001?\",\n",
    "        \"What are the company holidays for 2025?\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for use_case in use_cases:\n",
    "    print(f\"ðŸ”„ Testing {use_case.title()} Use Case\\n\")\n",
    "\n",
    "    # Create chatbot for this use case\n",
    "    case_chatbot = RAGChatbot(use_case=use_case, enable_functions=True)\n",
    "\n",
    "    queries = test_scenarios[use_case]\n",
    "\n",
    "    for query in queries:\n",
    "        print(f\"Q: {query}\")\n",
    "        response = case_chatbot.chat(query)\n",
    "\n",
    "        # Truncate long responses for readability\n",
    "        answer = response['answer']\n",
    "        if len(answer) > 200:\n",
    "            answer = answer[:200] + \"...\"\n",
    "\n",
    "        print(f\"A: {answer}\")\n",
    "        print(f\"Method: {response['method']}\")\n",
    "        print()\n",
    "\n",
    "    print(\"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eba4cf",
   "metadata": {},
   "source": [
    "## 7. Interactive Chat Session\n",
    "\n",
    "Create an interactive chat session (run this cell and type your questions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8d7059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_chat_session():\n",
    "    \"\"\"Run an interactive chat session in the notebook.\"\"\"\n",
    "\n",
    "    print(\"ðŸ¤– Interactive Chat Session Started!\")\n",
    "    print(\"Choose your use case: 1) IT Helpdesk, 2) Customer Support, 3) HR Assistant\")\n",
    "    print(\"Type 'quit' to exit, 'switch' to change use case\\n\")\n",
    "\n",
    "    # Default chatbot\n",
    "    current_chatbot = RAGChatbot(\"it_helpdesk\")\n",
    "    current_use_case = \"it_helpdesk\"\n",
    "\n",
    "    print(f\"Current use case: {current_use_case}\")\n",
    "    print(\"Type your question below:\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"\\nYou: \").strip()\n",
    "\n",
    "            if user_input.lower() in ['quit', 'exit']:\n",
    "                print(\"Goodbye! ðŸ‘‹\")\n",
    "                break\n",
    "\n",
    "            elif user_input.lower() == 'switch':\n",
    "                print(\"Available use cases:\")\n",
    "                print(\"1. it_helpdesk\")\n",
    "                print(\"2. customer_support\")\n",
    "                print(\"3. hr_assistant\")\n",
    "\n",
    "                choice = input(\"Enter choice (1-3): \").strip()\n",
    "                use_case_map = {\n",
    "                    '1': 'it_helpdesk',\n",
    "                    '2': 'customer_support',\n",
    "                    '3': 'hr_assistant'\n",
    "                }\n",
    "\n",
    "                if choice in use_case_map:\n",
    "                    current_use_case = use_case_map[choice]\n",
    "                    current_chatbot = RAGChatbot(current_use_case)\n",
    "                    print(f\"Switched to {current_use_case}\")\n",
    "                else:\n",
    "                    print(\"Invalid choice\")\n",
    "                continue\n",
    "\n",
    "            elif not user_input:\n",
    "                continue\n",
    "\n",
    "            # Process the question\n",
    "            response = current_chatbot.chat(user_input)\n",
    "\n",
    "            print(f\"\\nðŸ¤– Bot: {response['answer']}\")\n",
    "\n",
    "            # Show method used\n",
    "            method_icons = {\n",
    "                'function_calling': 'ðŸ”§',\n",
    "                'rag_retrieval': 'ðŸ“š',\n",
    "                'fallback': 'ðŸ’­'\n",
    "            }\n",
    "\n",
    "            icon = method_icons.get(response['method'], 'ðŸ¤–')\n",
    "            print(f\"\\n{icon} Method: {response['method']}\")\n",
    "\n",
    "            if response.get('function_calls_made'):\n",
    "                print(f\"ðŸ”§ Function calls: {response['function_calls_made']}\")\n",
    "\n",
    "            if response.get('sources'):\n",
    "                print(f\"ðŸ“š Sources: {', '.join(response['sources'][:2])}\")\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nGoodbye! ðŸ‘‹\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Uncomment the line below to start interactive session\n",
    "# interactive_chat_session()\n",
    "\n",
    "print(\"ðŸ’¡ Uncomment the last line in this cell to start an interactive chat session!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d726ae",
   "metadata": {},
   "source": [
    "## 8. Performance and Statistics\n",
    "\n",
    "Let's analyze the performance and statistics of our RAG system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7279d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "def performance_test():\n",
    "    \"\"\"Run performance tests on the RAG system.\"\"\"\n",
    "\n",
    "    print(\"âš¡ Running Performance Tests...\\n\")\n",
    "\n",
    "    # Test queries for each use case\n",
    "    test_data = {\n",
    "        \"it_helpdesk\": [\n",
    "            \"computer slow\",\n",
    "            \"password reset\",\n",
    "            \"printer issue\",\n",
    "            \"check printer01 status\",\n",
    "            \"VPN connection\"\n",
    "        ],\n",
    "        \"customer_support\": [\n",
    "            \"track order\",\n",
    "            \"return policy\",\n",
    "            \"order ORD123456 status\",\n",
    "            \"shipping cost\",\n",
    "            \"payment methods\"\n",
    "        ],\n",
    "        \"hr_assistant\": [\n",
    "            \"time off request\",\n",
    "            \"benefits info\",\n",
    "            \"employee EMP001 leave\",\n",
    "            \"company holidays\",\n",
    "            \"training courses\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    results = defaultdict(list)\n",
    "\n",
    "    for use_case, queries in test_data.items():\n",
    "        print(f\"Testing {use_case}...\")\n",
    "\n",
    "        chatbot = RAGChatbot(use_case, enable_functions=True)\n",
    "\n",
    "        for query in queries:\n",
    "            start_time = time.time()\n",
    "            response = chatbot.chat(query)\n",
    "            end_time = time.time()\n",
    "\n",
    "            duration = end_time - start_time\n",
    "            results[use_case].append({\n",
    "                'query': query,\n",
    "                'duration': duration,\n",
    "                'method': response['method'],\n",
    "                'success': response['success']\n",
    "            })\n",
    "\n",
    "    # Analyze results\n",
    "    print(\"\\nðŸ“Š Performance Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    for use_case, case_results in results.items():\n",
    "        durations = [r['duration'] for r in case_results]\n",
    "        avg_duration = sum(durations) / len(durations)\n",
    "        min_duration = min(durations)\n",
    "        max_duration = max(durations)\n",
    "\n",
    "        success_rate = sum(1 for r in case_results if r['success']) / len(case_results)\n",
    "\n",
    "        rag_count = sum(1 for r in case_results if r['method'] == 'rag_retrieval')\n",
    "        func_count = sum(1 for r in case_results if r['method'] == 'function_calling')\n",
    "\n",
    "        print(f\"\\n{use_case.title()}:\")\n",
    "        print(f\"  Average Response Time: {avg_duration:.2f}s\")\n",
    "        print(f\"  Min/Max Response Time: {min_duration:.2f}s / {max_duration:.2f}s\")\n",
    "        print(f\"  Success Rate: {success_rate:.1%}\")\n",
    "        print(f\"  RAG Responses: {rag_count}, Function Calls: {func_count}\")\n",
    "\n",
    "performance_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaafb80",
   "metadata": {},
   "source": [
    "## 9. Summary and Next Steps\n",
    "\n",
    "This notebook has demonstrated the complete RAG chatbot system with:\n",
    "\n",
    "### âœ… Completed Features:\n",
    "- **FAISS Vector Store**: Fast document similarity search\n",
    "- **RAG Pipeline**: Langchain-based retrieval and generation\n",
    "- **Function Calling**: Azure OpenAI dynamic function execution\n",
    "- **Multiple Use Cases**: IT Helpdesk, Customer Support, HR Assistant\n",
    "- **Mock Data**: Comprehensive datasets for testing\n",
    "\n",
    "### ðŸš€ Usage Options:\n",
    "1. **Command Line**: `python chatbot_main.py --use-case it_helpdesk`\n",
    "2. **Web Interface**: `streamlit run streamlit_app.py`\n",
    "3. **Jupyter Notebook**: This interactive demo\n",
    "\n",
    "### ðŸ”§ Customization:\n",
    "- Add new use cases in `mock_data/`\n",
    "- Extend functions in `rag_system/function_calling.py`\n",
    "- Modify prompts in `rag_system/retrieval_chain.py`\n",
    "- Adjust vector search parameters in `rag_system/vector_store.py`\n",
    "\n",
    "### ðŸ“ˆ Performance Considerations:\n",
    "- Vector search is typically fast (< 1s)\n",
    "- Function calls add latency but provide real-time data\n",
    "- RAG retrieval provides contextually accurate responses\n",
    "- Conversation history maintains context across interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db518c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸŽ‰ RAG Chatbot System Demo Completed!\")\n",
    "print(\"\\nðŸ“ Key Takeaways:\")\n",
    "print(\"â€¢ Vector search enables fast, relevant document retrieval\")\n",
    "print(\"â€¢ RAG combines retrieval with generation for accurate responses\")\n",
    "print(\"â€¢ Function calling provides dynamic, real-time data access\")\n",
    "print(\"â€¢ Multiple use cases show system versatility\")\n",
    "print(\"â€¢ Modular design allows easy customization and extension\")\n",
    "\n",
    "print(\"\\nðŸ”— Next Steps:\")\n",
    "print(\"1. Configure your .env file with Azure OpenAI credentials\")\n",
    "print(\"2. Install requirements: pip install -r requirements.txt\")\n",
    "print(\"3. Run the web interface: streamlit run streamlit_app.py\")\n",
    "print(\"4. Customize for your specific use case\")\n",
    "print(\"5. Deploy to production environment\")\n",
    "\n",
    "print(\"\\nâœ¨ Happy coding!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
